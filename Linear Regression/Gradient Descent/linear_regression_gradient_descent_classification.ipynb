{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('spambase.data').read().split(\"\\n\")\n",
    "data = [i.split(\",\") for i in (data)]\n",
    "column = open('features','r').read().split(\"\\n\")\n",
    "column =[i.strip() for i in column]\n",
    "dataset =  pd.DataFrame(data, columns=column)\n",
    "dataset=dataset.convert_objects(convert_numeric=True)\n",
    "dataset=dataset.dropna()\n",
    "columnmax = [max(dataset[i]) for i in dataset.columns]\n",
    "columnmin = [min(dataset[i]) for i in dataset.columns]\n",
    "for i,j in enumerate(dataset.columns):\n",
    "    dataset[j] = (dataset[j] - columnmin[i])/columnmax[i]\n",
    "dataset['class']= dataset['class'].astype(int)\n",
    "# dataset.insert(0,'Bias',1)\n",
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared(W,X,Y):\n",
    "    return np.sum((np.dot(X,np.transpose(W))-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(learning_rate,initial_weights,m,dataset,bias):\n",
    "    diff = 10000000000\n",
    "    Y = np.asarray(list(dataset['class']))\n",
    "    X = dataset.drop(columns=['class']).values\n",
    "    X=np.insert(X, 0, bias, axis=1)\n",
    "    XT=np.transpose(X)\n",
    "    w_old = initial_weights\n",
    "    d_old = mean_squared(initial_weights,X,Y)\n",
    "    lm = learning_rate/m\n",
    "    while diff >0.0000000000001:\n",
    "        w_new = (w_old - (lm * (np.dot(XT,(np.dot(X,w_old.T))-Y))))\n",
    "        d_new = mean_squared(w_new,X,Y)\n",
    "        diff = abs(d_new-d_old)\n",
    "        d_old=(d_new)\n",
    "        w_old =(w_new)\n",
    "    return w_old\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(row,weights,bias):\n",
    "    Y=(row['class'])\n",
    "    X = np.asarray(list(row[:-1]))\n",
    "    X=np.insert(X,0,bias)\n",
    "    \n",
    "    s=0\n",
    "    for i in range(len(X)):\n",
    "        s+=(X[i]*weights[i])\n",
    "    if s>0.37:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction,test_dataset):\n",
    "    test=list(test_dataset['class'])\n",
    "    ac = zip(prediction,test)\n",
    "    right =0\n",
    "    for k,v in ac:\n",
    "        if k ==v:\n",
    "            right+=1\n",
    "    return right/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.39299825 0.55174253 0.56168443 0.19327727 0.40465526 0.82273622\n",
      " 0.60593554 0.57121773 0.33656865 0.65489134 0.73217497 0.34301635\n",
      " 0.57961998 0.06333794 0.31255584 0.60858662 0.19133326 0.67919943\n",
      " 0.18512852 0.02748675 0.4250278  0.68598184 0.06342571 0.61019324\n",
      " 0.5076199  0.96461375 0.5235876  0.02356952 0.44922418 0.81473418\n",
      " 0.45877409 0.23025861 0.08328027 0.79113764 0.99634023 0.0358845\n",
      " 0.1766804  0.26002473 0.09195485 0.28009451 0.40534903 0.34275486\n",
      " 0.47168701 0.11012816 0.34209395 0.03057115 0.27942145 0.65264778\n",
      " 0.04084037 0.58805968 0.1926489  0.96885098 0.23811038 0.2326728\n",
      " 0.78985254 0.49753629 0.72942491 0.17630391]\n",
      "0.9\n",
      "920\n",
      "[0.37059793 0.41185311 0.06103179 0.49219974 0.71031292 0.59547945\n",
      " 0.57415927 0.18555549 0.68602442 0.24854752 0.71846804 0.85859282\n",
      " 0.51893769 0.85513412 0.22124309 0.83490906 0.04613238 0.83229833\n",
      " 0.48377504 0.43348703 0.33045174 0.4919946  0.09601654 0.85965718\n",
      " 0.10609379 0.66712466 0.17269047 0.02583054 0.03936076 0.01696185\n",
      " 0.08649101 0.66573401 0.24522512 0.63354139 0.49163077 0.46614882\n",
      " 0.30678083 0.02131582 0.82700235 0.53616077 0.27075537 0.67834578\n",
      " 0.11224794 0.91603791 0.46397034 0.85082427 0.00998506 0.10032926\n",
      " 0.15130808 0.20281887 0.50843401 0.64719698 0.19575593 0.36067596\n",
      " 0.01449309 0.56947708 0.51800859 0.88101739]\n",
      "0.9010869565217391\n",
      "1840\n",
      "[0.29013483 0.54980383 0.71465738 0.23603894 0.93584951 0.16939891\n",
      " 0.27725146 0.31566403 0.26903203 0.06758013 0.15261171 0.07692306\n",
      " 0.66515503 0.15149579 0.70960374 0.3335247  0.97614844 0.63328578\n",
      " 0.30381671 0.79926873 0.81987686 0.90395471 0.24801821 0.86662224\n",
      " 0.44070321 0.11261041 0.10616602 0.94779647 0.04969565 0.86230344\n",
      " 0.09407158 0.96915902 0.54886434 0.05582863 0.50457406 0.22318971\n",
      " 0.60563555 0.64537834 0.52578648 0.14728447 0.29736936 0.21765374\n",
      " 0.94106039 0.49512431 0.17609982 0.18710872 0.70389668 0.60748481\n",
      " 0.33738934 0.96412741 0.20636369 0.70562396 0.81255207 0.0467444\n",
      " 0.33036167 0.11757845 0.88290241 0.064809  ]\n",
      "0.9152173913043479\n",
      "2760\n",
      "[1.10522555e-01 5.45934615e-01 9.96329120e-02 4.45395922e-01\n",
      " 7.58037539e-01 7.25123173e-01 1.37610970e-01 9.40189526e-01\n",
      " 5.96903478e-01 4.08332245e-01 9.22187999e-01 1.63446542e-01\n",
      " 5.61707677e-01 7.43541556e-01 1.10497697e-01 3.75973628e-01\n",
      " 2.93739778e-01 8.36101011e-01 2.25054695e-01 3.47943599e-01\n",
      " 7.27700065e-01 7.05470209e-01 6.26336264e-01 3.44605567e-02\n",
      " 3.21746208e-01 3.49718954e-01 6.88145904e-01 4.00115341e-01\n",
      " 9.53241369e-01 2.30625407e-01 9.97799356e-01 4.35900790e-01\n",
      " 6.51790589e-01 5.55963840e-01 5.17776867e-01 8.18582239e-02\n",
      " 7.48756725e-01 5.38618250e-01 6.65801385e-01 9.63795051e-01\n",
      " 3.73017830e-02 5.15187132e-01 5.05700468e-01 7.02275586e-01\n",
      " 5.56065226e-01 5.97079909e-01 9.52594174e-01 4.17095422e-01\n",
      " 4.64132002e-01 6.44413012e-01 2.33156205e-01 3.84707998e-01\n",
      " 2.67803518e-02 2.72192709e-01 5.05792289e-04 7.95786362e-01\n",
      " 7.60331969e-01 1.76520151e-01]\n",
      "0.8869565217391304\n",
      "3680\n",
      "[0.92022764 0.74907602 0.83402779 0.48649622 0.74005604 0.25517559\n",
      " 0.40535346 0.64915863 0.79266293 0.64807005 0.85064122 0.09242591\n",
      " 0.19409005 0.23904923 0.41463357 0.00192991 0.17736846 0.51541064\n",
      " 0.07227366 0.30018208 0.44285247 0.246527   0.27072507 0.97254752\n",
      " 0.72977633 0.63265297 0.19176728 0.88160264 0.860438   0.22873137\n",
      " 0.59185203 0.75215688 0.19158108 0.25785169 0.70831985 0.99120408\n",
      " 0.01808852 0.86148668 0.91247491 0.43410211 0.01264214 0.82401614\n",
      " 0.29505339 0.24667528 0.30669338 0.21362591 0.41942686 0.37637437\n",
      " 0.63700969 0.3690784  0.10727238 0.77601887 0.55956808 0.90133547\n",
      " 0.36922122 0.19787922 0.42220742 0.58554696]\n",
      "0.8923913043478261\n",
      "4600\n",
      "0.8991304347826088\n",
      "0\n",
      "[0.71668607 0.4477182  0.22291068 0.52447399 0.25777541 0.23413929\n",
      " 0.74944845 0.97259032 0.9128736  0.36752815 0.10865405 0.65309294\n",
      " 0.83331092 0.0726777  0.69627495 0.77484761 0.40976775 0.06805043\n",
      " 0.23780252 0.25147758 0.00350023 0.5463261  0.49393515 0.03981925\n",
      " 0.96054379 0.05635098 0.40339928 0.55367997 0.3863575  0.4657879\n",
      " 0.79814544 0.85707672 0.9439044  0.43967664 0.69854711 0.41948202\n",
      " 0.00253332 0.95429074 0.59041159 0.29193823 0.27195354 0.6519654\n",
      " 0.88803838 0.34730958 0.47591478 0.89478887 0.3735725  0.93004254\n",
      " 0.91149678 0.63977835 0.45134658 0.36572555 0.87790725 0.38608757\n",
      " 0.84931696 0.9944486  0.35455137 0.67709297]\n",
      "0.9\n",
      "920\n",
      "[0.74013581 0.88482745 0.74522934 0.94387879 0.93468715 0.0993957\n",
      " 0.89679327 0.80667123 0.71411049 0.41034357 0.72757543 0.45546779\n",
      " 0.86141483 0.51773813 0.57412635 0.30308682 0.56550505 0.60438887\n",
      " 0.28933728 0.05047197 0.55136125 0.70555645 0.01348556 0.49474052\n",
      " 0.09837493 0.31371682 0.38856575 0.30358485 0.96036984 0.65066824\n",
      " 0.51051179 0.05033156 0.9781263  0.58126007 0.8030713  0.45377766\n",
      " 0.31515383 0.49248822 0.5780479  0.4372774  0.04673645 0.94249152\n",
      " 0.67507783 0.98006782 0.42614639 0.02430577 0.53449715 0.17308525\n",
      " 0.46622964 0.76212978 0.68350628 0.90995581 0.38213989 0.80617464\n",
      " 0.97751011 0.4736322  0.06210297 0.15863418]\n",
      "0.9010869565217391\n",
      "1840\n",
      "[0.66001542 0.45628936 0.23566123 0.5952024  0.47262318 0.75907559\n",
      " 0.36229915 0.10698084 0.71766426 0.04579121 0.35006276 0.68706006\n",
      " 0.94351999 0.69474717 0.32794676 0.17651615 0.85172986 0.4023909\n",
      " 0.9210794  0.33812642 0.09439076 0.28669934 0.30929535 0.44689873\n",
      " 0.17026756 0.91372257 0.3808853  0.70389579 0.88233553 0.71482543\n",
      " 0.91613621 0.69754008 0.39138079 0.26193239 0.31413341 0.65188959\n",
      " 0.89034702 0.98660286 0.45345859 0.00400808 0.25503657 0.7259993\n",
      " 0.22612089 0.35962691 0.62042592 0.85188541 0.99567205 0.75408274\n",
      " 0.25467649 0.67951494 0.64799694 0.63308776 0.8596716  0.33086454\n",
      " 0.08596019 0.90937976 0.65847018 0.23453977]\n",
      "0.9152173913043479\n",
      "2760\n",
      "[0.22710626 0.05461172 0.31821216 0.39201337 0.80189128 0.18178992\n",
      " 0.97639494 0.04271209 0.04220332 0.39669218 0.87268297 0.2165894\n",
      " 0.70565122 0.96953199 0.41614893 0.61661324 0.62275203 0.01332035\n",
      " 0.55162541 0.97146088 0.65608772 0.60219793 0.53809753 0.26664425\n",
      " 0.55521454 0.08610452 0.63464783 0.60787199 0.12161105 0.04476209\n",
      " 0.34475581 0.01635029 0.4397138  0.04793716 0.60713255 0.19567241\n",
      " 0.96653251 0.48381247 0.96388046 0.65125419 0.85891279 0.83276554\n",
      " 0.88491227 0.57114952 0.99190624 0.65716493 0.22453393 0.38398011\n",
      " 0.5482423  0.93324976 0.30298138 0.91214376 0.69180218 0.10628748\n",
      " 0.46997736 0.75947603 0.23382944 0.91249879]\n",
      "0.8869565217391304\n",
      "3680\n",
      "[0.71474671 0.19424723 0.96261906 0.7158889  0.33737059 0.4245209\n",
      " 0.02056791 0.12659223 0.71862737 0.6612009  0.51476123 0.70609911\n",
      " 0.97300562 0.67488804 0.05915141 0.62124833 0.82089825 0.25774519\n",
      " 0.49773808 0.59245267 0.40192817 0.27223771 0.61615969 0.25996319\n",
      " 0.02169749 0.33426261 0.1074312  0.18200714 0.30976567 0.65463191\n",
      " 0.24821132 0.21479327 0.45712669 0.33215814 0.27034407 0.87979618\n",
      " 0.99848364 0.62465551 0.73475029 0.55885562 0.87027957 0.1935992\n",
      " 0.77151128 0.03632741 0.0397479  0.62627094 0.76832978 0.05262941\n",
      " 0.76624976 0.0019391  0.61762068 0.46739335 0.55817213 0.26404985\n",
      " 0.46170725 0.88366619 0.69461924 0.49979798]\n",
      "0.8923913043478261\n",
      "4600\n",
      "0.8991304347826088\n",
      "0\n",
      "[0.71384215 0.6479791  0.0215981  0.74516952 0.89912079 0.50956631\n",
      " 0.91446205 0.33083379 0.57592132 0.53307204 0.7301187  0.48778555\n",
      " 0.45503799 0.08137719 0.41889163 0.2658563  0.72451937 0.56098096\n",
      " 0.08741032 0.99511267 0.58545983 0.49082543 0.54351661 0.80689635\n",
      " 0.4643426  0.53607437 0.4575505  0.27636322 0.92618369 0.17739225\n",
      " 0.02239526 0.20979468 0.24645808 0.37645405 0.19897944 0.07264791\n",
      " 0.52834159 0.58349719 0.37549611 0.96481631 0.44032348 0.42448825\n",
      " 0.4185981  0.89941972 0.49873622 0.95317285 0.16038939 0.62095714\n",
      " 0.50720256 0.78884825 0.01469704 0.54411044 0.87780344 0.29268283\n",
      " 0.8588276  0.5738335  0.4350154  0.93601665]\n",
      "0.9\n",
      "920\n",
      "[0.63013078 0.74511846 0.12134968 0.91202798 0.27644331 0.93117114\n",
      " 0.6372848  0.93350894 0.2132407  0.26890371 0.54805188 0.53578676\n",
      " 0.13383432 0.91536083 0.25217256 0.63576512 0.18769363 0.4342429\n",
      " 0.22539227 0.36917865 0.23262991 0.48603563 0.14440591 0.42263086\n",
      " 0.44803615 0.34647741 0.5937998  0.42175341 0.31942924 0.19043118\n",
      " 0.61552928 0.11451626 0.69911917 0.0266217  0.71633309 0.27517029\n",
      " 0.44622557 0.27403529 0.80969514 0.13241566 0.8816881  0.82915768\n",
      " 0.34276421 0.36386274 0.59360385 0.99747138 0.6324601  0.79173091\n",
      " 0.83667185 0.75051926 0.80412903 0.3347969  0.74899463 0.27266471\n",
      " 0.6664749  0.13668882 0.35422346 0.28076982]\n",
      "0.9010869565217391\n",
      "1840\n",
      "[0.29013755 0.48615112 0.33092244 0.29974739 0.57065495 0.15975952\n",
      " 0.37330954 0.06034551 0.6348827  0.56665781 0.05234604 0.96792094\n",
      " 0.99003599 0.672228   0.77106598 0.73402883 0.54224426 0.81599467\n",
      " 0.74128071 0.69641075 0.64886034 0.47374683 0.95760503 0.22803394\n",
      " 0.89217016 0.63758133 0.91083814 0.78861876 0.42478201 0.23275076\n",
      " 0.69870432 0.26969271 0.43481642 0.33473807 0.18096714 0.82412023\n",
      " 0.70919626 0.05576634 0.45016049 0.18823778 0.32786946 0.25587625\n",
      " 0.47237481 0.6998193  0.48746749 0.38455992 0.49265128 0.48044147\n",
      " 0.1536528  0.59570131 0.21157756 0.85573375 0.31097043 0.16342755\n",
      " 0.72184066 0.05637672 0.02392311 0.12240686]\n",
      "0.9152173913043479\n",
      "2760\n",
      "[0.46759219 0.65324364 0.64983288 0.69030047 0.83721597 0.64506395\n",
      " 0.25964214 0.30766827 0.36722835 0.57868701 0.36389948 0.78849857\n",
      " 0.81408433 0.2236392  0.00792985 0.32572225 0.45020127 0.13933654\n",
      " 0.53319079 0.44144127 0.67270161 0.23107404 0.02612996 0.60268173\n",
      " 0.97310067 0.03101754 0.94729792 0.14451292 0.40937854 0.97793232\n",
      " 0.2681791  0.47181751 0.09675366 0.63584949 0.21773939 0.61452716\n",
      " 0.68311929 0.94603488 0.54401647 0.90560371 0.13946679 0.23128544\n",
      " 0.79829339 0.46164822 0.11739047 0.06604742 0.9922097  0.35521033\n",
      " 0.91250701 0.76078122 0.25649828 0.5485103  0.1661965  0.36996924\n",
      " 0.59772596 0.0738141  0.51523382 0.68908959]\n",
      "0.8869565217391304\n",
      "3680\n",
      "[0.85819641 0.51862885 0.00969926 0.12727592 0.97880223 0.4201663\n",
      " 0.27960512 0.69000707 0.65730761 0.43545671 0.73666464 0.18019797\n",
      " 0.68722169 0.54398895 0.40278334 0.00771949 0.83461186 0.40753377\n",
      " 0.00200074 0.79710781 0.40302091 0.30424002 0.51590329 0.07496423\n",
      " 0.86615946 0.52482547 0.40566636 0.11558942 0.54771753 0.22125669\n",
      " 0.86230783 0.41166336 0.79953599 0.54809181 0.9424811  0.02314794\n",
      " 0.47164553 0.05927588 0.44348007 0.26448699 0.32925693 0.84978354\n",
      " 0.43872792 0.77834033 0.3900306  0.52462318 0.45378752 0.55257772\n",
      " 0.81822151 0.45739066 0.69384563 0.42897056 0.55911611 0.85071139\n",
      " 0.72229132 0.11835839 0.52532833 0.5978897 ]\n",
      "0.8923913043478261\n",
      "4600\n",
      "0.8991304347826088\n",
      "0\n",
      "[0.75533234 0.10458337 0.43452323 0.96573852 0.31373086 0.53348707\n",
      " 0.55954407 0.64031013 0.49041919 0.40614764 0.93825898 0.87923789\n",
      " 0.40669558 0.61424017 0.66825662 0.78522721 0.11039065 0.74058025\n",
      " 0.4871476  0.56367939 0.09639509 0.30242845 0.61028863 0.64736999\n",
      " 0.64253815 0.48172492 0.77839486 0.95250496 0.94058314 0.02787734\n",
      " 0.34839397 0.56495472 0.29598059 0.652965   0.31245876 0.38796938\n",
      " 0.1594323  0.65838864 0.14960726 0.46468825 0.93069986 0.32695962\n",
      " 0.99320977 0.16878462 0.37417355 0.27814679 0.75335554 0.40256308\n",
      " 0.98795407 0.94765716 0.43629299 0.83565694 0.76571247 0.66472226\n",
      " 0.64498575 0.99911916 0.59946093 0.10574028]\n",
      "0.9\n",
      "920\n",
      "[0.03832357 0.96321054 0.37380507 0.94525593 0.63176347 0.79502349\n",
      " 0.94750416 0.07067805 0.20569055 0.5282031  0.8581447  0.54654413\n",
      " 0.60918328 0.97995036 0.37128311 0.69027908 0.72662919 0.4597359\n",
      " 0.47878315 0.07499036 0.5103234  0.72423151 0.2070518  0.77937132\n",
      " 0.89755153 0.72823283 0.21866758 0.41381743 0.52620505 0.94284823\n",
      " 0.44585201 0.0559934  0.36258214 0.16005084 0.87201117 0.64007415\n",
      " 0.87598704 0.63191367 0.1429035  0.78275983 0.24246296 0.85876694\n",
      " 0.79851508 0.77510087 0.40774261 0.39253952 0.17542608 0.0790125\n",
      " 0.22730395 0.2214567  0.78732736 0.38449716 0.58883224 0.98574765\n",
      " 0.45952864 0.66375864 0.31961816 0.45290013]\n",
      "0.9010869565217391\n",
      "1840\n",
      "[0.52502721 0.08447073 0.76796198 0.37867274 0.23135097 0.02922828\n",
      " 0.58142931 0.96904715 0.21962248 0.6939431  0.8385521  0.80586809\n",
      " 0.41990162 0.58532759 0.45828641 0.58451631 0.63559537 0.84763466\n",
      " 0.41753264 0.87943578 0.50895384 0.99979992 0.10398472 0.44271019\n",
      " 0.17889361 0.21044968 0.30798873 0.99399213 0.38267672 0.69049584\n",
      " 0.98774835 0.22238856 0.57791212 0.85771706 0.18788129 0.70514935\n",
      " 0.49776346 0.97271792 0.45757695 0.194368   0.2575812  0.47954777\n",
      " 0.13252006 0.27431595 0.48449189 0.36972223 0.28956677 0.83313901\n",
      " 0.21682341 0.83832515 0.23674333 0.31630836 0.56557621 0.47602937\n",
      " 0.7767843  0.92615352 0.79925913 0.87042268]\n",
      "0.9152173913043479\n",
      "2760\n",
      "[0.67099752 0.6931571  0.61914175 0.58797036 0.16971379 0.20907392\n",
      " 0.61144383 0.84874336 0.31498376 0.50060768 0.88204495 0.22664262\n",
      " 0.72913599 0.03822707 0.75105559 0.85468188 0.01030017 0.2686386\n",
      " 0.4583441  0.00488761 0.23819078 0.50159898 0.54593092 0.01690927\n",
      " 0.57451296 0.38795979 0.81840121 0.82333722 0.27673577 0.34290802\n",
      " 0.04960255 0.41225119 0.38113089 0.02754492 0.98184927 0.76541307\n",
      " 0.38250756 0.80628258 0.2775325  0.20159166 0.65988056 0.86284893\n",
      " 0.4748326  0.80696259 0.80821541 0.80668737 0.21622031 0.64770941\n",
      " 0.77990416 0.45968882 0.18558812 0.48410743 0.70752933 0.05818953\n",
      " 0.83210472 0.12260849 0.55308829 0.68395084]\n",
      "0.8869565217391304\n",
      "3680\n",
      "[0.74116946 0.3849232  0.82242431 0.87677761 0.54371337 0.70515049\n",
      " 0.32799481 0.17120752 0.00293391 0.47895898 0.89592043 0.4348537\n",
      " 0.23474544 0.50112131 0.79100714 0.49463499 0.42530587 0.40118052\n",
      " 0.58236214 0.87970999 0.32496899 0.40822033 0.37299922 0.7964776\n",
      " 0.58188156 0.85825738 0.40584804 0.11797368 0.16779687 0.50864419\n",
      " 0.64769722 0.08669023 0.69014026 0.94548664 0.10930319 0.97338141\n",
      " 0.81461122 0.82045458 0.95181201 0.32625295 0.34575497 0.1891189\n",
      " 0.53930383 0.60047491 0.18100372 0.27343726 0.39437088 0.90093319\n",
      " 0.14907546 0.03631378 0.43350934 0.56116377 0.3997663  0.27435491\n",
      " 0.59250821 0.39932359 0.54830692 0.95492144]\n",
      "0.8923913043478261\n",
      "4600\n",
      "0.8991304347826088\n",
      "0\n",
      "[0.50390454 0.26823884 0.48298273 0.50536995 0.39434113 0.80854356\n",
      " 0.79610093 0.94013603 0.28936456 0.62460706 0.12889871 0.61674808\n",
      " 0.01864425 0.67087599 0.42718473 0.26108176 0.65751281 0.45156914\n",
      " 0.07960617 0.33401875 0.892162   0.29576042 0.2941003  0.68633091\n",
      " 0.65323258 0.31948749 0.85373822 0.96193216 0.62902521 0.93732288\n",
      " 0.69993112 0.10676313 0.20415849 0.66366341 0.81567601 0.35288658\n",
      " 0.48019148 0.80685424 0.78687998 0.71017701 0.55697538 0.97164051\n",
      " 0.31505666 0.8673766  0.23633666 0.06105683 0.2170786  0.1023242\n",
      " 0.3224862  0.06731692 0.96705618 0.64334753 0.32217809 0.17926167\n",
      " 0.62564928 0.7912937  0.34688401 0.24758248]\n",
      "0.9\n",
      "920\n",
      "[0.06767304 0.32669683 0.51041008 0.85827454 0.57901689 0.20998436\n",
      " 0.60181741 0.90652319 0.23444851 0.05742751 0.03160443 0.28654194\n",
      " 0.38302681 0.60584015 0.23555238 0.04626169 0.84443233 0.64106727\n",
      " 0.1835816  0.53001962 0.54765536 0.53417534 0.86163084 0.52465167\n",
      " 0.90742206 0.15689751 0.19835255 0.03300433 0.26995334 0.58615273\n",
      " 0.93175016 0.64565761 0.22620692 0.86364296 0.49057595 0.14577136\n",
      " 0.05374184 0.51498207 0.18323625 0.72073771 0.67735433 0.80273325\n",
      " 0.1783081  0.43831134 0.03542105 0.32672225 0.69484018 0.86991343\n",
      " 0.5944731  0.69063253 0.10551096 0.93577673 0.21698386 0.38372805\n",
      " 0.67196962 0.19930062 0.57942581 0.91392358]\n",
      "0.9010869565217391\n",
      "1840\n",
      "[0.19366003 0.41056085 0.9877795  0.77336036 0.85972654 0.84970109\n",
      " 0.64131302 0.86617363 0.85393346 0.07511301 0.18327675 0.08366155\n",
      " 0.15878495 0.15775709 0.8928785  0.60341179 0.21054245 0.98430998\n",
      " 0.28916221 0.96588898 0.86935522 0.12593301 0.70758396 0.0170543\n",
      " 0.32647595 0.25231194 0.16211167 0.06472578 0.3608014  0.63680901\n",
      " 0.35000517 0.7365282  0.57886042 0.54784252 0.51657806 0.19381509\n",
      " 0.82799361 0.58176889 0.23436298 0.43860784 0.92472842 0.55430776\n",
      " 0.47468953 0.33371267 0.44287055 0.92628184 0.84382783 0.19352748\n",
      " 0.98913806 0.25023111 0.01100016 0.80037846 0.53296106 0.9804251\n",
      " 0.51103335 0.37264143 0.85984671 0.07085195]\n",
      "0.9152173913043479\n",
      "2760\n",
      "[0.70685083 0.63808416 0.19291347 0.72715938 0.99437113 0.22654473\n",
      " 0.31580156 0.8807831  0.40572165 0.87923346 0.56852658 0.59610047\n",
      " 0.95161204 0.22799201 0.09959284 0.09945107 0.05567687 0.6134348\n",
      " 0.42042631 0.20659533 0.11600541 0.78195552 0.60591531 0.95974174\n",
      " 0.79391533 0.32580717 0.36395332 0.36633449 0.66854434 0.5721212\n",
      " 0.75604836 0.88903444 0.22957839 0.63903199 0.28894679 0.27847728\n",
      " 0.4100922  0.48547885 0.46974955 0.85651922 0.40477166 0.73409122\n",
      " 0.69729775 0.99570025 0.03162367 0.97326308 0.3691163  0.01835538\n",
      " 0.89179662 0.7963506  0.13327829 0.5284726  0.86444933 0.91264441\n",
      " 0.49893728 0.14148527 0.70185805 0.20653839]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dd56016feee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m920\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-475883db58b7>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(learning_rate, initial_weights, m, dataset, bias)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0.0000000000001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0md_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_new\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1)\n",
    "\n",
    "b=0\n",
    "while b<=0.5:\n",
    "    ac=[]\n",
    "    for i in range(0,len(dataset),920):\n",
    "        print(i)\n",
    "        if i+920<len(dataset):\n",
    "            bias=0.13   \n",
    "            training_dataset=pd.concat([dataset[i+920:],dataset[0:i]])\n",
    "            n = len(training_dataset.columns)-1\n",
    "            m = len(training_dataset)\n",
    "            W=np.random.rand(n+1)\n",
    "            print(W)\n",
    "            test_dataset=dataset[i:i+920]\n",
    "            weights=training(0.9,W,m,training_dataset,bias)\n",
    "            prediction=[]\n",
    "            for index,row in test_dataset.iterrows():\n",
    "                prediction.append(testing(row,weights,bias))\n",
    "            acc = accuracy(prediction,test_dataset)\n",
    "            print(acc)\n",
    "            ac.append(acc)\n",
    "    print(np.sum(np.asarray(ac))/5)\n",
    "    b+=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62263766, 0.9335026 , 0.29797037, ..., 0.15312717, 0.61044247,\n",
       "       0.72430497])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.asarray([1,2,3])\n",
    "b = np.asarray([[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(b,np.transpose(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
