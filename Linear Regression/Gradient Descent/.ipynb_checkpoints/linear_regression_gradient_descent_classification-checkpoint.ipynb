{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaivalpatel/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: FutureWarning: convert_objects is deprecated.  To re-infer data dtypes for object columns, use DataFrame.infer_objects()\n",
      "For all other conversions use the data-type specific converters pd.to_datetime, pd.to_timedelta and pd.to_numeric.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open('spambase.data').read().split(\"\\n\")\n",
    "data = [i.split(\",\") for i in (data)]\n",
    "column = open('features','r').read().split(\"\\n\")\n",
    "column =[i.strip() for i in column]\n",
    "dataset =  pd.DataFrame(data, columns=column)\n",
    "dataset=dataset.convert_objects(convert_numeric=True)\n",
    "dataset=dataset.dropna()\n",
    "columnmax = [max(dataset[i]) for i in dataset.columns]\n",
    "columnmin = [min(dataset[i]) for i in dataset.columns]\n",
    "for i,j in enumerate(dataset.columns):\n",
    "    dataset[j] = (dataset[j] - columnmin[i])/columnmax[i]\n",
    "dataset['class']= dataset['class'].astype(int)\n",
    "# dataset.insert(0,'Bias',1)\n",
    "dataset['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared(W,X,Y):\n",
    "    return np.sum((np.dot(X,np.transpose(W))-Y)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(learning_rate,initial_weights,m,dataset,bias):\n",
    "    diff = 10000000000\n",
    "    Y = np.asarray(list(dataset['class']))\n",
    "    X = dataset.drop(columns=['class']).values\n",
    "    X=np.insert(X, 0, bias, axis=1)\n",
    "    XT=np.transpose(X)\n",
    "    w_old = initial_weights\n",
    "    d_old = mean_squared(initial_weights,X,Y)\n",
    "    lm = learning_rate/m\n",
    "    while diff >0.0000000000001:\n",
    "        w_new = (w_old - (lm * (np.dot(XT,(np.dot(X,w_old.T))-Y))))\n",
    "        d_new = mean_squared(w_new,X,Y)\n",
    "        diff = abs(d_new-d_old)\n",
    "        d_old=(d_new)\n",
    "        w_old =(w_new)\n",
    "    return w_old\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(row,weights,bias):\n",
    "    Y=(row['class'])\n",
    "    X = np.asarray(list(row[:-1]))\n",
    "    X=np.insert(X,0,bias)\n",
    "    \n",
    "    s=0\n",
    "    for i in range(len(X)):\n",
    "        s+=(X[i]*weights[i])\n",
    "    if w_sum>0.37:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(prediction,test_dataset):\n",
    "    test=list(test_dataset['class'])\n",
    "    ac = zip(prediction,test)\n",
    "    right =0\n",
    "    for k,v in ac:\n",
    "        if k ==v:\n",
    "            right+=1\n",
    "    return right/len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.64487497 0.17522986 0.33995882 0.01954566 0.88143324 0.91746452\n",
      " 0.18183615 0.5365826  0.42393731 0.47509667 0.45060533 0.06942445\n",
      " 0.4961199  0.74840716 0.18065963 0.25241034 0.21817531 0.10929768\n",
      " 0.2426998  0.06298901 0.80622202 0.78543045 0.62693186 0.20390462\n",
      " 0.35049976 0.88327499 0.73833622 0.51709212 0.52659729 0.36940172\n",
      " 0.97700677 0.23117874 0.12534932 0.99950444 0.07452296 0.28486724\n",
      " 0.46475322 0.1586191  0.4535429  0.85847382 0.91017541 0.1383842\n",
      " 0.3779353  0.77292164 0.22002801 0.51986649 0.87019121 0.97243127\n",
      " 0.2394242  0.35206761 0.04691031 0.50194238 0.06490679 0.53358123\n",
      " 0.44635825 0.64041998 0.09852083 0.90161234]\n",
      "920\n",
      "[0.46013107 0.60036648 0.99784069 0.03085854 0.00693498 0.04840379\n",
      " 0.08575089 0.18762531 0.18385306 0.32381538 0.31857168 0.79309456\n",
      " 0.80784611 0.09661985 0.28930063 0.38641609 0.2140119  0.23035757\n",
      " 0.89432459 0.2586848  0.25804943 0.28042603 0.67998792 0.216241\n",
      " 0.8268814  0.17459604 0.62373182 0.41003015 0.52191541 0.01766905\n",
      " 0.47856021 0.9012406  0.53748736 0.18097045 0.27884419 0.96795155\n",
      " 0.17259225 0.80389414 0.56127769 0.63658642 0.82641188 0.08528982\n",
      " 0.54704468 0.11556093 0.84253695 0.90040561 0.09101674 0.02063285\n",
      " 0.46930616 0.87141399 0.4423558  0.71467173 0.9706445  0.31911705\n",
      " 0.83086915 0.4044362  0.90009363 0.80006685]\n",
      "1840\n",
      "[0.38498856 0.90307639 0.82032465 0.54645391 0.63302749 0.66139773\n",
      " 0.00564131 0.43272469 0.68399228 0.66582155 0.91014357 0.69876151\n",
      " 0.19118275 0.03172882 0.25231613 0.02997327 0.60010822 0.30961988\n",
      " 0.42308884 0.926499   0.22873559 0.11213165 0.95685844 0.64431709\n",
      " 0.41602822 0.40786817 0.30344482 0.48035107 0.04077881 0.35481366\n",
      " 0.11750152 0.19472172 0.34024657 0.24640918 0.9912528  0.0435475\n",
      " 0.90382223 0.30317147 0.34124634 0.60837795 0.54954234 0.40414786\n",
      " 0.84176232 0.47279486 0.81437105 0.24632146 0.80940398 0.01242631\n",
      " 0.37888972 0.60805955 0.49314375 0.34238664 0.07043962 0.90457512\n",
      " 0.65989928 0.67697567 0.68988931 0.02264866]\n",
      "2760\n",
      "[0.87490966 0.67048968 0.51215584 0.79846595 0.69054249 0.00575662\n",
      " 0.08511251 0.40236407 0.19525234 0.68346626 0.21663378 0.7154921\n",
      " 0.02742773 0.85117193 0.92666871 0.19293814 0.50837346 0.20329408\n",
      " 0.33025254 0.38154772 0.69502329 0.29957084 0.27999656 0.9482796\n",
      " 0.91705545 0.24656887 0.06163109 0.84297652 0.10801248 0.3322494\n",
      " 0.11915759 0.92923737 0.16444313 0.59953019 0.76825846 0.77784541\n",
      " 0.04447488 0.8375301  0.36582524 0.28765199 0.58727154 0.16186523\n",
      " 0.51856275 0.22553389 0.78862955 0.21390146 0.09906897 0.34379166\n",
      " 0.78314347 0.98374052 0.48862849 0.96573589 0.55004885 0.35881644\n",
      " 0.33517211 0.39192196 0.52292432 0.40344259]\n",
      "3680\n",
      "[0.17488476 0.80648931 0.64291437 0.68926552 0.7143818  0.87882335\n",
      " 0.94002047 0.73583921 0.21131909 0.79741613 0.76521657 0.96786416\n",
      " 0.95735129 0.33953878 0.0496286  0.6768542  0.6638436  0.4783249\n",
      " 0.89862995 0.63124084 0.88634999 0.83087901 0.90579225 0.59594952\n",
      " 0.60246058 0.11188725 0.61009515 0.72773942 0.71608642 0.0229489\n",
      " 0.76305256 0.34221516 0.87663848 0.73084768 0.4501311  0.92713965\n",
      " 0.98823115 0.42996713 0.5912026  0.08090546 0.94715968 0.58442528\n",
      " 0.12728134 0.0164802  0.69898429 0.33596853 0.29211509 0.16568426\n",
      " 0.24493513 0.07755367 0.50887705 0.26237612 0.52798931 0.44161044\n",
      " 0.67651883 0.2846696  0.42419706 0.3251015 ]\n",
      "4600\n",
      "0.0\n",
      "0\n",
      "[0.43144405 0.5532819  0.52797163 0.33161432 0.11884207 0.68786844\n",
      " 0.71907509 0.04948861 0.86722797 0.83513866 0.91163566 0.82418764\n",
      " 0.42450048 0.64097715 0.36345927 0.68521496 0.77039483 0.36942606\n",
      " 0.66160318 0.7514048  0.54332641 0.08269318 0.87354333 0.54095575\n",
      " 0.24236454 0.23283568 0.02618372 0.79756232 0.24575049 0.9834829\n",
      " 0.50361045 0.55324765 0.32489185 0.87191546 0.09798764 0.89441226\n",
      " 0.36219438 0.34080618 0.06090688 0.85697234 0.17927262 0.89683423\n",
      " 0.052344   0.5456039  0.80268586 0.65457375 0.03019069 0.81816621\n",
      " 0.19919837 0.96601907 0.78514075 0.2459443  0.56546938 0.9339155\n",
      " 0.58191713 0.68783005 0.88760938 0.25851318]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-07ec0240c13a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mtest_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m920\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtraining_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mprediction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-475883db58b7>\u001b[0m in \u001b[0;36mtraining\u001b[0;34m(learning_rate, initial_weights, m, dataset, bias)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mdiff\u001b[0m \u001b[0;34m>\u001b[0m\u001b[0;36m0.0000000000001\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mw_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw_old\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlm\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw_old\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0md_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_new\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_new\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0md_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0md_old\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6b119f3583c5>\u001b[0m in \u001b[0;36mmean_squared\u001b[0;34m(W, X, Y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmean_squared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1)\n",
    "\n",
    "b=0\n",
    "while b<=0.5:\n",
    "    ac=[]\n",
    "    for i in range(0,len(dataset),920):\n",
    "        print(i)\n",
    "        if i+920<len(dataset):\n",
    "            bias=0.13   \n",
    "            training_dataset=pd.concat([dataset[i+920:],dataset[0:i]])\n",
    "            n = len(training_dataset.columns)-1\n",
    "            m = len(training_dataset)\n",
    "            W=np.random.rand(n+1)\n",
    "            print(W)\n",
    "            test_dataset=dataset[i:i+920]\n",
    "            weights=training(0.9,W,m,training_dataset,bias)\n",
    "            prediction=[]\n",
    "            for index,row in test_dataset.iterrows():\n",
    "                prediction.append(testing(row,weights,bias))\n",
    "            acc = accuracy(prediction,test_dataset)\n",
    "            print(acc)\n",
    "            ac.append(acc)\n",
    "    print(np.sum(np.asarray(ac))/5)\n",
    "    b+=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62263766, 0.9335026 , 0.29797037, ..., 0.15312717, 0.61044247,\n",
       "       0.72430497])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.asarray([1,2,3])\n",
    "b = np.asarray([[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(b,np.transpose(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 3]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
